# Main-Project-Used-Car-Price-Prediction
Used car price prediction is a machine learning technique that uses a car's features, such as its year, mileage, make, model, and fuel type, to estimate its current market value. The goal is to overcome the difficulties of subjective pricing in the used car market by providing an objective, data-driven valuation for sellers and buyers.


> üî¨ A data-driven machine learning project that predicts diabetes subtypes using genetic, environmental and lifestyle factors.

---

## üß© Project Overview

This project uses a comprehensive dataset encompassing multiple diabetes subtypes, including Steroid‚ÄëInduced Diabetes, Neonatal Diabetes Mellitus (NDM), Prediabetes, Type 1 Diabetes, and Wolfram Syndrome. The dataset includes medical, genetic, environmental, and lifestyle attributes to provide a holistic view of each patient‚Äôs profile. The aim is to help researchers and healthcare professionals understand how these factors interact and contribute to the development and progression of different diabetes subtypes, enabling insights for personalized treatment, risk assessment, and improved disease management.

### üéØ Objectives
- Predict the diabetes subtype from patient health indicators.  
- Identify key predictors of each subtype.  
- Evaluate multiple models and select the best-performing classifier.  

---

### ‚ñ∂Ô∏è Quick Start
1. Open the notebook:
### ‚ñ∂Ô∏è Run Directly in Google Colab
You can execute the entire workflow without any setup:
üîó [**Open Project in Colab**](https://colab.research.google.com/drive/1G_jjmFN5ur6ABKDNm6I8A5J6T5J658Eb?usp=sharing)
#### Codes and Resources Used
- **Editor Used:** Google Colab / Jupyter Notebook  
- **Python Version:** 3.12  
- **Platform:** Google Colab  
- **Environment:** Machine Learning / Health Informatics  

#### Python Packages Used
- **General Purpose:** `os`, `warnings`, `joblib`, `requests`  
- **Data Manipulation:** `pandas`, `numpy`  
- **Data Visualization:** `matplotlib`, `seaborn`, `plotly`  
- **Machine Learning:** `scikit-learn`, `xgboost`

# Data
The dataset is a crucial part of this project. It combines clinical, genetic, environmental, and lifestyle features to predict diabetes subtypes.

I structure this as follows - 

## Source Data
**Description:** Contains 70,000 patient samples with 34 features including genetic markers, autoantibodies, family history, environmental factors, lifestyle attributes, and clinical measures.

**Target Feature:** Diabetes_Subtype with 13 classes:
0: Steroid-Induced Diabetes
1: Neonatal Diabetes Mellitus (NDM)
2: Prediabetic
3: Type 1 Diabetes
4: Wolfram Syndrome
5: LADA
6: Type 2 Diabetes
7: Wolcott-Rallison Syndrome
8: Secondary Diabetes
9: Type 3c Diabetes
10: Gestational Diabetes
11: Cystic Fibrosis‚ÄëRelated Diabetes (CFRD)
12: MODY

## Data Acquisition
- Data can be downloaded directly from the repository or other open-source sources.

- In some cases, data may be collected via API calls or web scraping (elaborate if applicable).

- Ensure all license restrictions and credits are properly followed.
## Data Preprocessing
To make the dataset suitable for modeling:

1.Checked for missing values ‚Üí none found

2.Verified duplicate rows ‚Üí none found

3.Removed outliers using IQR method

4.Applied skewness correction and transformations (log/square root)

5.Scaled numeric features using StandardScaler / MinMaxScaler

6.Encoded categorical variables using one-hot encoding or label encoding

## üìäüìä Workflow Steps

| Step                       | Description                                             |
| -------------------------- | ------------------------------------------------------- |
| 1Ô∏è‚É£ Load Dataset           | Import raw data into environment                        |
| 2Ô∏è‚É£ Initial EDA            | Analyze distributions, missing values, outliers         |
| 3Ô∏è‚É£ Data Preprocessing     | Handle nulls, outliers, encode categorical features     |
| 4Ô∏è‚É£ Feature Engineering    | Create new features or transform existing ones          |
| 5Ô∏è‚É£ Feature Scaling        | Standardize or normalize numeric features               |
| 6Ô∏è‚É£ Feature Selection      | Select top features using SelectKBest                   |
| 7Ô∏è‚É£ Train/Test Split       | Divide dataset into training and testing sets           |
| 8Ô∏è‚É£ Model Building         | Train multiple machine learning models                  |
| 9Ô∏è‚É£ Hyperparameter Tuning  | Optimize model parameters using RandomizedSearchCV      |
| üîü Model Evaluation        | Evaluate using Accuracy, F1, Precision, Recall, AUC-ROC |
| 1Ô∏è‚É£1Ô∏è‚É£ Final Prediction    | Predict diabetes subtype for new patient samples        |
| 1Ô∏è‚É£2Ô∏è‚É£ Future Enhancements | Deep learning, ensemble methods, deployment             |



#### üìä Dataset
- **Rows √ó Columns:** Rows √ó Columns: 70,000 √ó 34

- **Features include:** genetic markers, autoantibodies, family history, environmental factors, lifestyle attributes, clinical measures

- **No missing values or duplicates**

#### ü§ñ Model Building
#### üß© Algorithms Used

The following machine learning algorithms were implemented and compared to identify the best-performing model for multiclass diabetes subtype prediction:

- Random Forest Classifier üå≤

- Logistic Regression üìà

- Naive Bayes Classifier üßÆ

- Decision Tree Classifier üå≥

- Gradient Boosting Classifier üöÄ

- Support Vector Machine (SVM) ‚öôÔ∏è

- K-Nearest Neighbors (KNN) üë•

#### üéØ Model Tuning

**Hyperparameter Optimization:** Conducted using RandomizedSearchCV (3-fold cross-validation)

**Parameters fine-tuned include:**

- Number of estimators

- Maximum depth

- Learning rate (for boosting models)

- Regularization parameters

- Kernel type and C value (for SVM)

#### üß† Model Evaluation Metrics

Each model was evaluated using multiple metrics to ensure balanced performance across all diabetes subtypes:

#### Metric	Description
| Metric                   | Description                                             |
| :----------------------- | :------------------------------------------------------ |
| **Accuracy**             | Overall proportion of correctly classified samples      |
| **Precision**            | Fraction of correctly predicted positive observations   |
| **Recall (Sensitivity)** | Fraction of actual positives correctly identified       |
| **F1-Score**             | Harmonic mean of Precision and Recall                   |
| **AUC-ROC**              | Measures model's ability to distinguish between classes |

#### üèÜ Best Model

#### After comprehensive evaluation:

#### Best Performing Model: üèÖ Random Forest Classifier

#### Reason for Selection:

- Highest accuracy and AUC-ROC scores

- Well-balanced precision‚Äìrecall trade-off

- High interpretability through feature importance

- Robust performance against noise and feature correlations

#### üìà Sample Prediction
#### Sample Input

| Feature              | Value |
| -------------------- | ----- |
| Age                  | 45    |
| Blood Pressure       | 130   |
| Blood Glucose Levels | 210   |
| BMI                  | 29.3  |
| Genetic Marker 1     | 1     |
| Family History       | Yes   |
| Physical Activity    | Low   |
| Diet Score           | 6     |

#### Sample Output

| Diabetes Subtype         | Probability |
| ------------------------ | ----------- |
| Prediabetes              | 0.65        |
| Type 1 Diabetes          | 0.15        |
| Steroid-Induced Diabetes | 0.05        |
| Wolfram Syndrome         | 0.02        |
| NDM                      | 0.13        |

#### Predicted Subtype: Prediabetes

**Top Contributing Features:** Genetic Marker 1, BMI, Diet Score

## Final Conclusion

1.A comprehensive machine learning pipeline was developed to predict diabetes subtypes using clinical, genetic, environmental, and lifestyle factors.

2.Multiple models were trained and evaluated: Random Forest, Logistic Regression, Naive Bayes, Decision Tree, Gradient Boosting, SVM, and KNN.

3.Random Forest emerged as the best-performing model, achieving 92% accuracy and high performance across Precision, Recall, F1-Score, and AUC-ROC metrics.

4.Key predictive features include: BMI, Blood Glucose Levels, Genetic Marker 1, Diet Score, Insulin Levels, and Family History.

5.The model effectively captures complex interactions between genetic, lifestyle, and clinical factors, providing interpretable insights for diabetes subtype prediction.

6.This project demonstrates the potential of machine learning in healthcare analytics for early detection, personalized risk assessment, and targeted interventions.

7.Future work can include deep learning models, ensemble methods, explainable AI (SHAP/LIME), and deployment as a web/mobile application.

# üöÄ Future Enhancements
Outline potential future work that can be done to extend the project or improve its functionality. This will help others understand the scope of your project and identify areas where they can contribute.
**1.Hyperparameter Optimization:** Use finer GridSearch or Bayesian optimization.

**2.Feature Engineering:** Add derived features, feature selection, or PCA.

**3.Class Imbalance Handling:** Use SMOTE or class weighting.

**4.Ensemble Learning:** Explore stacking or boosting (XGBoost, LightGBM).

**5.Data Expansion:** Incorporate additional genetic/environmental/lifestyle factors.

**6.Deployment & Monitoring:** Real-time prediction pipeline with continuous monitoring and retraining.

# Model Optimization

**1.Address Class Imbalance**

- Apply SMOTE, class weighting, or targeted oversampling/undersampling to improve predictions for underrepresented classes.

**2.Ensemble Techniques**

- Combine your trained models (Random Forest, Logistic Regression, Naive Bayes) using stacking to leverage complementary strengths.

- Explore boosting models like XGBoost, LightGBM, or CatBoost for higher predictive performance.

**3.Cross-Validation Enhancements**

- Use stratified k-fold cross-validation to ensure consistent performance across all classes.

- Monitor metrics per fold to detect potential overfitting

# Acknowledgments/References
Acknowledge any contributors, data sources, or other relevant parties who have contributed to the project. This is an excellent way to show your appreciation for those who have helped you along the way.
- Dataset inspired by open-source health data repositories

- Image credits: rashadashurov @ VectorStock

- README template adapted from Pragyy‚Äôs Data Science Readme Template


# License
Specify the license under which your code is released. Moreover, provide the licenses associated with the dataset you are using. This is important for others to know if they want to use or contribute to your project. 

For this github repository, the License used is [MIT License](https://opensource.org/license/mit/).
